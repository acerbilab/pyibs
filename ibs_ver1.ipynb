{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import psi, polygamma\n",
    "import time\n",
    "\n",
    "class IBS:\n",
    "    \n",
    "    \"\"\"\n",
    "    IBS class for computing the negative log-likelihood of a simulator based model.\n",
    "    \"\"\"\n",
    "    \n",
    "    # are we setting default options here?\n",
    "    \n",
    "    max_samples = 1e4 # maximum number of samples per function call\n",
    "    acceleration_threshold = 0.1 # keep accelerating until this threshold is reached (in s)\n",
    "    vectorized_threshold = 0.1 # maximum threshold for using vectorized algorithm (in s)\n",
    "    max_mem = 1e6 # maximum number of samples for vectorized implementation\n",
    "    negLogL_threshold = -np.inf # threshold for negative log-likelihood\n",
    " \n",
    "    \n",
    "    def __init__(self, fun, resp_mat, design_mat, vectorized = True, acceleration=1.5, num_samples_per_call=0, max_iter=1e5, max_time=np.inf):\n",
    " \n",
    "        self.fun = fun\n",
    "        self.resp_mat = np.atleast_1d(resp_mat)\n",
    "        self.design_mat = design_mat\n",
    "        self.vectorized = vectorized        # Use vectorized sampling algorithm with acceleration\n",
    "        self.acceleration = acceleration    # Acceleration factor for vectorized sampling\n",
    "        self.num_samples_per_call = num_samples_per_call    # Number of starting samples per trial per function call (0 = choose automatically)\n",
    "        self.max_iter = max_iter    # Maximum number of iterations (per trial and estimate)\n",
    "        self.max_time = max_time    # Maximum time for a IBS call (in seconds)\n",
    "\n",
    "    \n",
    "    def __call__(self, params, num_reps=10, trial_weights=None, return_var=False, return_positive=False, return_std=False):\n",
    "        # TO DO: add exitflags\n",
    "\n",
    "        t0 = time.perf_counter()\n",
    "        num_trials = self.resp_mat.shape[0]\n",
    "\n",
    "        # WEIGHT vector should be a scalar or same length as number of trials\n",
    "        weights = 1.0\n",
    "        if trial_weights is not None: weights = trial_weights.reshape(-1)\n",
    "        if not np.isscalar(weights) and len(weights) != num_trials: raise ValueError('trial_weights must have length num_trials')\n",
    "\n",
    "\n",
    "        sim_data = None\n",
    "        elapsed_time = 0\n",
    "        num_reps = int(num_reps)\n",
    "\n",
    "        # use vectorized or loop version?\n",
    "        if not type(self.vectorized) is bool:\n",
    "            if num_reps == 1: vectorized_flag = False\n",
    "            else:\n",
    "                start = time.time()\n",
    "                if self.design_mat is None:\n",
    "                    sim_data = self.fun(params, np.arange(num_trials))\n",
    "                else: sim_data = self.fun(params, self.design_mat)\n",
    "                elapsed_time = time.time() - start\n",
    "                vectorized_flag = elapsed_time < self.vectorized_threshold\n",
    "                \n",
    "        else: \n",
    "            vectorized_flag = self.vectorized\n",
    "            if num_reps == 1 and vectorized_flag:\n",
    "                vectorized_flag = False\n",
    "                raise Warning('Vectorized version of IBS is not available for num_reps = 1. Using loop version instead.')\n",
    "\n",
    "        def get_LL_from_K(psi_tab, K_mat):\n",
    "            \"\"\"\n",
    "            Convert matrix of K values into log-likelihoods.\n",
    "            \"\"\"\n",
    "            K_max = max(1, np.max(K_mat))\n",
    "            if K_max > len(psi_tab):   # Fill digamma function table\n",
    "                psi_tab = np.concatenate((psi_tab, psi(1) - psi(np.arange(len(psi_tab)+1, K_max+1))))\n",
    "            LL_mat = psi_tab[np.maximum(1, K_mat.astype(int)) - 1]\n",
    "            return LL_mat, psi_tab\n",
    "\n",
    "        def vecorized_ibs_sampling(params, sim_data0, elapsed_time0, t0, num_reps):\n",
    "            num_trials = self.resp_mat.shape[0]\n",
    "            trials = np.arange(num_trials) # enumerate the trials\n",
    "            num_samples_total = 0 # total number of samples drawn\n",
    "            func_count = 0\n",
    "            Psi_tab = []\n",
    "\n",
    "            # Empty matrix of K values (samples-to-hit) for each repeat for each trial\n",
    "            K_mat = np.zeros((num_reps, num_trials), dtype=int)\n",
    "\n",
    "            # Matrix of rep counts\n",
    "            K_place0 = np.tile(np.arange(num_reps)[:, np.newaxis], (1,num_trials))\n",
    "\n",
    "            # Current rep being sampled for each trial\n",
    "            Ridx = np.zeros(num_trials)\n",
    "\n",
    "            # Current vector of \"open\" K values per trial (not reached a \"hit\" yet)\n",
    "            K_open = np.zeros(num_trials)\n",
    "\n",
    "            target_hits = num_reps * np.ones(num_trials)\n",
    "            max_iter = self.max_iter * num_reps\n",
    "\n",
    "            if self.num_samples_per_call == 0:\n",
    "                samples_level = num_reps\n",
    "            else:\n",
    "                samples_level = self.num_samples_per_call\n",
    "            \n",
    "            for iter in range(max_iter):\n",
    "                # Pick trials that need more hits, sample multiple times\n",
    "                T = trials[Ridx < target_hits]\n",
    "                \n",
    "                if np.isfinite(self.max_time) and time.perf_counter() - t0 > self.max_time: \n",
    "                    T = np.empty(0)\n",
    "                    # add exitflag here\n",
    "\n",
    "                if len(T) == 0: break\n",
    "\n",
    "                num_consid_trials = len(T)\n",
    "\n",
    "                #With accelerated sampling, might request multiple samples at once\n",
    "                num_samples = min(max(1,np.round(samples_level)), self.max_samples)\n",
    "                max_samples = np.ceil(self.max_mem / num_consid_trials)\n",
    "                num_samples = min(num_samples, max_samples)\n",
    "                Tmat = np.tile(T, (int(num_samples),1))\n",
    "\n",
    "                # Simulate trials\n",
    "                if iter == 0 and num_samples == 1 and sim_data0 is not None:\n",
    "                    sim_data = sim_data0\n",
    "                    elapsed_time = elapsed_time0\n",
    "                else:\n",
    "                    # get the curret time \n",
    "                    start = time.time()\n",
    "                    if self.design_mat is None:\n",
    "                        sim_data = self.fun(params, Tmat.reshape(-1))\n",
    "                    else: \n",
    "                        sim_data = self.fun(params, self.design_mat[Tmat.reshape(-1)])\n",
    "                    func_count += 1\n",
    "                    elapsed_time = time.time() - start\n",
    "                \n",
    "                # Check that the returned simulated data have the right size\n",
    "                if len(sim_data) != np.size(Tmat): raise ValueError('ibslike:SizeMismatch',\n",
    "                    'Number of rows of returned simulated data does not match the number of requested trials.')\n",
    "                \n",
    "                num_samples_total += num_consid_trials\n",
    "\n",
    "                # Accelerated sampling\n",
    "                if self.acceleration > 0 and elapsed_time < self.acceleration_threshold:\n",
    "                    samples_level = samples_level * self.acceleration\n",
    "\n",
    "                # Check for hits\n",
    "                hits_temp = (self.resp_mat[Tmat.reshape(-1)] == sim_data)\n",
    "\n",
    "                # Build matrix of new hits (sandwich with buffer of hits, then removed)\n",
    "                hits_new = np.concatenate((np.ones((1,num_consid_trials)), hits_temp.reshape(Tmat.shape), np.ones((1,num_consid_trials))), axis=0)\n",
    "                \n",
    "                # Extract matrix of Ks from matrix of hits for this iteration\n",
    "                h = hits_new.shape[0]\n",
    "                list = np.nonzero(hits_new.ravel(order = 'F'))\n",
    "                row = np.ravel(np.floor_divide(list,h)).astype(int) + 1\n",
    "                col = np.mod(list,h) +1\n",
    "                delta = np.diff(np.append(col,1))\n",
    "                remove_idx = delta <= 0\n",
    "                row = row[~remove_idx]\n",
    "                delta = delta[~remove_idx]\n",
    "                index_col = np.nonzero(np.diff(np.concatenate((np.array([0]),row))))\n",
    "                col = 1 + np.arange(len(row)) - np.take(index_col,row-1)\n",
    "                K_iter = np.zeros((len(T),np.max(col)))\n",
    "                K_iter[row-1, col-1] = delta\n",
    "                \n",
    "                # Add K_open to first column of K_iter\n",
    "                K_iter[:,0] = K_iter[:,0] + K_open[T]\n",
    "\n",
    "                # Find last K position for each trial\n",
    "                index_last = np.argmin(np.hstack((K_iter, np.zeros(num_consid_trials).reshape(-1, 1))), axis=1) - 1\n",
    "                row_index = np.arange(len(T))\n",
    "                # Subtract one hit from last K (it was added)\n",
    "                K_iter[row_index, index_last] = K_iter[row_index, index_last] - 1\n",
    "                K_open[T] = K_iter[row_index, index_last]\n",
    "\n",
    "                # For each trial, ignore entries of K_iter past max # of reps\n",
    "                index_mat =  np.tile(np.arange(K_iter.shape[1])[:, np.newaxis], (1,num_consid_trials)) + Ridx[T]\n",
    "                K_iter[index_mat.T >= num_reps] = 0\n",
    "\n",
    "                # Find last K position for each trial again\n",
    "                index_last2 = np.argmin(np.hstack((K_iter, np.zeros(num_consid_trials).reshape(-1, 1))), axis=1) - 1\n",
    "\n",
    "                # Add current K to full K matrix\n",
    "                K_iter_place = (K_place0[:, :num_consid_trials] >= Ridx[T]) & (K_place0[:, :num_consid_trials] <= Ridx[T] + index_last2)\n",
    "                K_place = np.zeros_like(K_place0, dtype=bool)\n",
    "                K_place[:, T] = K_iter_place\n",
    "                K_mat_flat = K_mat.flatten('F')\n",
    "                K_mat_flat[K_place.flatten('F')] = K_iter[K_iter > 0].flatten()\n",
    "                K_mat = K_mat_flat.reshape(K_mat.shape, order='F')\n",
    "                Ridx[T] = Ridx[T] + index_last\n",
    "\n",
    "                # Compute log-likelihood only if requested for thresholding\n",
    "                if np.isfinite(self.negLogL_threshold):\n",
    "                    Rmin = np.min(Ridx[T])\n",
    "                    if Rmin >= K_mat.shape[0]: continue\n",
    "                    LL_temp, Psi_tab = get_LL_from_K(Psi_tab, K_mat[int(Rmin),:])\n",
    "                    nLL_temp = np.sum(LL_temp, axis = 0)\n",
    "                    if nLL_temp < self.negLogL_threshold:\n",
    "                        index_move = Ridx == Rmin\n",
    "                        Ridx[index_move] = Rmin + 1\n",
    "                        K_open[index_move] = 0\n",
    "                        # add exitflag\n",
    "\n",
    "            if len(T) != 0: raise RuntimeError('ibslike:ConvergenceError', 'Maximum number of iterations reached without convergence.')\n",
    "\n",
    "            # Compute log-likelihood\n",
    "            num_reps_per_trial = np.sum(K_mat > 0, axis=0) #number of repitions of the single trials \n",
    "            LL_mat, Psi_tab = get_LL_from_K(Psi_tab, K_mat)\n",
    "            nlogl = np.sum(LL_mat, axis=0)/num_reps_per_trial\n",
    "            K = K_mat.T\n",
    "\n",
    "            return nlogl, K, num_reps_per_trial, num_samples_total, func_count\n",
    "    \n",
    "        def loop_ibs_sampling(params, sim_data0, t0, num_reps):\n",
    "            num_trials = self.resp_mat.shape[0]\n",
    "            \n",
    "            trials = np.arange(num_trials) # enumerate the trials\n",
    "            max_iter = self.max_iter\n",
    "\n",
    "            K = np.zeros((num_trials, num_reps)) #saves the # of iterations needed for the sample to match the trial response\n",
    "            num_samples_total = 0 # total number of samples drawn\n",
    "            func_count = 0\n",
    "            psi_tab = []\n",
    "            for iRep in range(num_reps):\n",
    "                offset = 1\n",
    "                hits = np.full(num_trials,False)\n",
    "                if np.isfinite(self.max_time) and time.perf_counter() - t0 > self.max_time: break # add exitflag\n",
    "\n",
    "                for iter in range(max_iter):\n",
    "                    T = trials[hits == False]\n",
    "                    if len(T) == 0: break\n",
    "                    if iter == 0 and iRep == 0 and sim_data0 is not None:\n",
    "                        sim_data = sim_data0\n",
    "                        func_count += 1\n",
    "                    elif self.design_mat is None:\n",
    "                        # call function with input params only for the trials that have not been hit yet\n",
    "                        sim_data = self.fun(params, T)\n",
    "                    else:\n",
    "                        # call function with input params and design_mat only for the trials that have not been hit yet\n",
    "                        sim_data = self.fun(params, self.design_mat[T]) \n",
    "                        func_count += 1\n",
    "                        \n",
    "                    if np.shape(np.atleast_1d(sim_data))[0] != len(T): raise ValueError('ibslike:SizeMismatch',\n",
    "                    'Number of rows of returned simulated data does not match the number of requested trials.')\n",
    "                    num_samples_total += len(T)\n",
    "                    hits_new = (sim_data == self.resp_mat[T])\n",
    "                    hits[T] = hits_new\n",
    "\n",
    "                    K[np.atleast_1d(T)[hits_new], iRep] = offset\n",
    "                    offset += 1\n",
    "\n",
    "                    if np.isfinite(self.negLogL_threshold):\n",
    "                        K[hits == False, iRep] = offset\n",
    "                        LL_mat, psi_tab = get_LL_from_K(psi_tab, K[:, iRep])\n",
    "                        nlogl = np.sum(LL_mat, axis=0) # compute the negative log-likelihood of the current repetition\n",
    "                        if nlogl < self.negLogL_threshold: \n",
    "                            # add exitflag\n",
    "                            T = []\n",
    "                            break\n",
    "                    # Terminate if above maximum allowed runtime\n",
    "                    if np.isfinite(self.max_time) and time.perf_counter() - t0 > self.max_time: \n",
    "                        T = []\n",
    "                        break\n",
    "                \n",
    "                if len(T) != 0: raise RuntimeError('ibslike:ConvergenceError', 'Maximum number of iterations reached without convergence.')\n",
    "\n",
    "            num_reps_per_trail = np.sum(K > 0, axis=1) #number of repitions of the single trials \n",
    "            LL_mat, psi_tab = get_LL_from_K(psi_tab, K)\n",
    "            nlogl = np.sum(LL_mat, axis=1)/num_reps_per_trail\n",
    "\n",
    "            return nlogl, K, num_reps_per_trail, num_samples_total, func_count\n",
    "\n",
    "        if vectorized_flag:\n",
    "            nlogl, K, num_reps_per_trial, num_samples_total, func_count  = vecorized_ibs_sampling(params, sim_data, elapsed_time, t0, num_reps)\n",
    "        else:\n",
    "            nlogl, K, num_reps_per_trial, num_samples_total, func_count = loop_ibs_sampling(params, sim_data, t0, num_reps)\n",
    "        \n",
    "        nlogl = np.sum(nlogl*weights)\n",
    "        if return_positive: nlogl = np.abs(nlogl)\n",
    "        if return_var or return_std:\n",
    "            # compute variance of log-likelihood\n",
    "            K_max = np.amax(K, initial=1)\n",
    "            Ktab = - polygamma(1,np.arange(1, K_max + 1)) + polygamma(1,1)\n",
    "            LLvar = Ktab[np.maximum(1, K.astype(int)) - 1]\n",
    "            nlogl_var = np.sum(LLvar, axis=1)/num_reps_per_trial**2\n",
    "            nlogl_var = np.sum(nlogl_var*(weights**2))\n",
    "            if return_var: return nlogl, nlogl_var\n",
    "            if return_std: return nlogl, np.sqrt(nlogl_var)\n",
    "\n",
    "        # return more output: fun_count, num_samples/num_trials, elapsed_time\n",
    "        return nlogl"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
